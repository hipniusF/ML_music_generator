{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MUSIC GENERATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import functools\n",
    "from IPython import display as iphythondisplay\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import audio_helpers\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GET AND FORAMT DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get songs in ABC notation and save it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('songs_dataset.txt', 'r') as filehandle:\n",
    "    songs = json.load(filehandle)\n",
    " \n",
    "songs_joined = \"\\n\\n\".join(songs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create set with unique characters on songs and create look up table for parsing characters to id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = sorted(set(songs_joined))\n",
    "\n",
    "char2idx = {u: i for i, u in enumerate(vocab)}\n",
    "idx2char = np.array(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 83 unique characters in the dataset\n",
      "{\n",
      "  '\\n':   0,\n",
      "  ' ' :   1,\n",
      "  '!' :   2,\n",
      "  '\"' :   3,\n",
      "  '#' :   4,\n",
      "  \"'\" :   5,\n",
      "  '(' :   6,\n",
      "  ')' :   7,\n",
      "  ',' :   8,\n",
      "  '-' :   9,\n",
      "  '.' :  10,\n",
      "  '/' :  11,\n",
      "  '0' :  12,\n",
      "  '1' :  13,\n",
      "  '2' :  14,\n",
      "  '3' :  15,\n",
      "  '4' :  16,\n",
      "  '5' :  17,\n",
      "  '6' :  18,\n",
      "  '7' :  19,\n",
      "  ...\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Check vocab lenght and look up table\n",
    "print(\"There are\", len(vocab), \"unique characters in the dataset\")\n",
    "\n",
    "print('{')\n",
    "for char, _ in zip(char2idx, range(20)):\n",
    "    print('  {:4s}: {:3d},'.format(repr(char), char2idx[char]))\n",
    "print('  ...\\n}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorize string and songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_string(string):\n",
    "  array = np.array([])\n",
    "\n",
    "  for i, letter in enumerate(string):\n",
    "    array = np.append(array, char2idx[letter])\n",
    "\n",
    "  return array\n",
    "vectorized_songs = vectorize_string(songs_joined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'X:2\\nT:An B' ---- characters mapped to int ----> [49. 22. 14.  0. 45. 22. 26. 69.  1. 27.]\n"
     ]
    }
   ],
   "source": [
    "print ('{} ---- characters mapped to int ----> {}'.format(repr(songs_joined[:10]), vectorized_songs[:10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the batch for training and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(vectorized_songs, seq_length, batch_size):\n",
    "  # the length of the vectorized songs string\n",
    "  n = vectorized_songs.shape[0] - 1\n",
    "\n",
    "  # randomly choose the starting indices for the examples in the training batch\n",
    "  idx = np.random.choice(n-seq_length, batch_size)\n",
    "\n",
    "  input_batch = []\n",
    "  for starting_id in idx:\n",
    "    input_batch.append([int(vectorized_songs[x]) for x in range(starting_id, starting_id + seq_length)])\n",
    "\n",
    "    output_batch = []\n",
    "  for starting_id in idx:\n",
    "    output_batch.append([int(vectorized_songs[x]) for x in range(starting_id + 1, starting_id + seq_length + 1)])\n",
    "    \n",
    "  # x_batch, y_batch provide the true inputs and targets for network training\n",
    "  x_batch = np.reshape(input_batch, [batch_size, seq_length])\n",
    "  y_batch = np.reshape(output_batch, [batch_size, seq_length])\n",
    "  return x_batch, y_batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step   0\n",
      "  input: 61 ('f')\n",
      "  expected output: 15 ('3')\n",
      "Step   1\n",
      "  input: 15 ('3')\n",
      "  expected output: 60 ('e')\n",
      "Step   2\n",
      "  input: 60 ('e')\n",
      "  expected output: 1 (' ')\n",
      "Step   3\n",
      "  input: 1 (' ')\n",
      "  expected output: 59 ('d')\n",
      "Step   4\n",
      "  input: 59 ('d')\n",
      "  expected output: 60 ('e')\n"
     ]
    }
   ],
   "source": [
    "x_batch, y_batch = get_batch(vectorized_songs, seq_length=5, batch_size=1)\n",
    "\n",
    "for i, (input_idx, target_idx) in enumerate(zip(np.squeeze(x_batch), np.squeeze(y_batch))):\n",
    "    print(\"Step {:3d}\".format(i))\n",
    "    print(\"  input: {} ({:s})\".format(input_idx, repr(idx2char[input_idx])))\n",
    "    print(\"  expected output: {} ({:s})\".format(target_idx, repr(idx2char[target_idx])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CREATE MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM(rnn_units): \n",
    "  return tf.keras.layers.LSTM(\n",
    "    rnn_units, \n",
    "    return_sequences=True, \n",
    "    recurrent_initializer='glorot_uniform',\n",
    "    recurrent_activation='sigmoid',\n",
    "    stateful=True,\n",
    "  )\n",
    "\n",
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "  model = tf.keras.Sequential([\n",
    "    # Layer 1: Embedding layer to transform indices into dense vectors \n",
    "    #   of a fixed embedding size\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim, batch_input_shape=[batch_size, None]),\n",
    "\n",
    "    # Layer 2: LSTM with `rnn_units` number of units. \n",
    "    LSTM(rnn_units),\n",
    "\n",
    "    # Layer 3: Dense (fully-connected) layer that transforms the LSTM output\n",
    "    #   into the vocabulary size. \n",
    "    tf.keras.layers.Dense(vocab_size)\n",
    "  ])\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create testing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (32, None, 256)           21248     \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (32, None, 1024)          5246976   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (32, None, 83)            85075     \n",
      "=================================================================\n",
      "Total params: 5,353,299\n",
      "Trainable params: 5,353,299\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model(len(vocab), embedding_dim=256, rnn_units=1024, batch_size=32)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing testing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape:       (32, 100)  # (batch_size, sequence_length)\n",
      "Prediction shape:  (32, 100, 83) # (batch_size, sequence_length, vocab_size)\n"
     ]
    }
   ],
   "source": [
    "x, y = get_batch(vectorized_songs, seq_length=100, batch_size=32)\n",
    "pred = model(x)\n",
    "print(\"Input shape:      \", x.shape, \" # (batch_size, sequence_length)\")\n",
    "print(\"Prediction shape: \", pred.shape, \"# (batch_size, sequence_length, vocab_size)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAINING MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(labels, logits):\n",
    "  loss = tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
    "  return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing computing loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[4.4252005 4.419723  4.4189105 ... 4.433098  4.416784  4.418725 ]\n",
      " [4.4218187 4.4199104 4.426529  ... 4.418541  4.416278  4.418387 ]\n",
      " [4.4187436 4.4172697 4.410074  ... 4.40803   4.4240737 4.417233 ]\n",
      " ...\n",
      " [4.420402  4.418879  4.416252  ... 4.4275875 4.419402  4.415432 ]\n",
      " [4.415121  4.4118032 4.4210467 ... 4.417624  4.427172  4.4147053]\n",
      " [4.422515  4.4239388 4.4260674 ... 4.4318023 4.4202704 4.404405 ]], shape=(32, 100), dtype=float32)\n",
      "Prediction shape:  (32, 100, 83)  # (batch_size, sequence_length, vocab_size)\n",
      "scalar_loss:       4.41972\n"
     ]
    }
   ],
   "source": [
    "example_batch_loss = compute_loss(y, pred)\n",
    "print(example_batch_loss)\n",
    "print(\"Prediction shape: \", pred.shape, \" # (batch_size, sequence_length, vocab_size)\") \n",
    "print(\"scalar_loss:      \", example_batch_loss.numpy().mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRAINING PARAMETERS OPTIMIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Hyperparameter setting and optimization ###\n",
    "\n",
    "# Optimization parameters:\n",
    "num_training_iterations = 10000  # Increase this to train longer\n",
    "batch_size = 20  # Experiment between 1 and 64\n",
    "seq_length = 150  # Experiment between 50 and 500\n",
    "learning_rate = 1e-4  # Experiment between 1e-5 and 1e-1\n",
    "\n",
    "# Model parameters: \n",
    "vocab_size = len(vocab)\n",
    "embedding_dim = 256 \n",
    "rnn_units = 1024  # Experiment between 1 and 2048\n",
    "\n",
    "# Checkpoint location: \n",
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"my_ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [17:16<00:00,  9.64it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Define optimizer and training operation ###\n",
    "model = build_model(len(vocab), embedding_dim, rnn_units, batch_size)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "@tf.function\n",
    "def train_step(x, y): \n",
    "  # Use tf.GradientTape()\n",
    "  with tf.GradientTape() as tape:\n",
    "  \n",
    "    y_hat = model(x)\n",
    "  \n",
    "    loss = compute_loss(y, y_hat)\n",
    "\n",
    "  # Now, compute the gradients \n",
    "  grads = tape.gradient(loss, model.trainable_variables)\n",
    "  \n",
    "  # Apply the gradients to the optimizer so it can update the model accordingly\n",
    "  optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "  return loss\n",
    "\n",
    "##################\n",
    "# Begin training!#\n",
    "##################\n",
    "\n",
    "history = []\n",
    "# plotter = plt.plot(sec=2, xlabel='Iterations', ylabel='Loss')\n",
    "if hasattr(tqdm, '_instances'): tqdm._instances.clear() # clear if it exists\n",
    "\n",
    "for iter in tqdm(range(num_training_iterations)):\n",
    "\n",
    "  # Grab a batch and propagate it through the network\n",
    "  x_batch, y_batch = get_batch(vectorized_songs, seq_length, batch_size)\n",
    "  loss = train_step(x_batch, y_batch)\n",
    "\n",
    "  # Update the progress bar\n",
    "  history.append(loss.numpy().mean())\n",
    "  plt.plot(history)\n",
    "\n",
    "  # Update the model with the changed weights!\n",
    "  if iter % 100 == 0:     \n",
    "    model.save_weights(checkpoint_prefix)\n",
    "    \n",
    "# Save the trained model and the weights\n",
    "model.save_weights(checkpoint_prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GENERATING MUSIC USING THE MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restore the latest checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (1, None, 256)            21248     \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (1, None, 1024)           5246976   \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (1, None, 83)             85075     \n",
      "=================================================================\n",
      "Total params: 5,353,299\n",
      "Trainable params: 5,353,299\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model(len(vocab), embedding_dim, rnn_units, batch_size=1)\n",
    "\n",
    "# Restore the model weights for the last checkpoint after training\n",
    "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "model.build(tf.TensorShape([1, None]))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Prediction of a generated song ###\n",
    "\n",
    "def generate_text(model, start_string, generation_length=1000):\n",
    "  # Evaluation step (generating ABC text using the learned RNN model)\n",
    "\n",
    "  input_eval = vectorize_string(start_string)\n",
    "  input_eval = tf.expand_dims(input_eval, 0)\n",
    "\n",
    "  # Empty string to store our results\n",
    "  text_generated = []\n",
    "\n",
    "  # Here batch size == 1\n",
    "  model.reset_states()\n",
    "  tqdm._instances.clear()\n",
    "\n",
    "  for i in tqdm(range(generation_length)):\n",
    "      predictions = model(input_eval)\n",
    "      \n",
    "      # Remove the batch dimension\n",
    "      predictions = tf.squeeze(predictions, 0)\n",
    "      \n",
    "      predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
    "      \n",
    "      # Pass the prediction along with the previous hidden state\n",
    "      #   as the next inputs to the model\n",
    "      input_eval = tf.expand_dims([predicted_id], 0)\n",
    "      \n",
    "      # Hint: consider what format the prediction is in vs. the output\n",
    "      text_generated.append(idx2char[predicted_id])\n",
    "    \n",
    "  return (start_string + ''.join(text_generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:03<00:00, 329.45it/s]\n"
     ]
    }
   ],
   "source": [
    "generated_text = generate_text(model, start_string=\"X\", generation_length=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'XlLL:9\\n3Th[e 7WCP3V8mQdSVXUJR6N,\\'pQ,tJiS^CU[[h]BkN8!-N<CG5CK8c_mt7CqRQrsje)mFNbqOi\\n<7m]wKc6Fye!y0Xt\\n8hp H|IxEqIJom>f)WUqIyOU\\nZZ4Y#qq>Qv6UNT]EjIQI=jU.5RX.S_\\ngE#pTTL9.kMU[[kV8C,3#Z3)))\"k5uaUX]LJ.o0yrhlWReoJsUHPR1#9VTGYq-SQZVIDXJE,j:vT<_MI8tMKYtlQL)Q_\"]mXn\"OP0 xZhtkK TNTTp5RW,)psJy\\n<XxY=kQT.70EHVTiPh9O>,IYCTovwwZhpt#\"Z_lPyQs,\"NI#cZiy6AT5<xILUw00FY^.LQONJwR<O.Zyt07.WVIO<MK\\np)nX<IOp)xpyUp\\nJqoQfQ\\'UvOjY#l)<iVIn>k65kQQtNf7V7Jl|<1Su\\nKp\"_lJ\\'zs6O>_]\\'lnVOSzU\"8U4ij\\',G/i_-HTH88\"omln#GiOO 6\\'TL]7>CmLgID2qJytMqNuw=G)_cYgJqJ9HwXsm[6KX9KY1q^bqK##9W[Y7SWTq4Z)xIKD)jSrMA=P/^5UMjq8LPVYPZ:lukK>\"TXQZYkJaq\"C\"\"QxGQ#k1P RS7q<._v)NZMPL[mJ\"[tHStvXZ3ZX]05JVWj<V.uVU7lxO)R2MkIQNksIjH(#D-S(45]QMqM0VV(LT]LwUQ5I\"UHk4RS,mMJNs,>Ub\\'UJ9k0fl]8KtuZw#qTT<K]QUmT<OC.[\"\")Ay5RyLW)C)Z#N9H<BwIM/#\"hZ-8hZ5N[9-zw!m(SqTi#h4IP)O3 imiVImzLMU>TNYn._>7Tp\"\"]7IR<PGU5XjVZ5Zc^mRY<<PtO G^RkLj#g\\nkvU^xz#IHqbqyR]POIwQqykl_y8yM_MGnhN\\'M/>Tm4!LT2)_0_(.m^Jz|!c<O0vhyKh>41,X=|k^Y=V|I2SHwawx<:[8pq9[9Dv !Tjgfq)I6A,SV!\\n.8YM\"qB8<qLSfCqVmlt/62s2t\"Jr)qS_j[Z\"jTJi'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.mandolintab.net/abcconverter.php\n",
      "Found 3 songs in text\n",
      "X:147\n",
      "T:Spolsing Mown\n",
      "Z: id:dc-jig-142\n",
      "M:6/8\n",
      "L:1/8\n",
      "K:A Dorian\n",
      "B|cBd efe|d2B GBA|GEB dBG|cde fed|!\n",
      "fge d2B|AGF GED|]!\n",
      "X:52\n",
      "T:Bugf of Stursqon\n",
      "Z: id:dc-jig-79\n",
      "M:6/8\n",
      "L:1/8\n",
      "K:D Major\n",
      "A|dAA BAG|ABA ABA|dABA dfed|cABG A2dB|A2AG FAAB|G2ED CEGA|!\n",
      "GABd gefg|afef g2ed|edcd eged|dcAB cAG2:|!\n",
      "X:130\n",
      "T:Futh Kasley\n",
      "Z: id:dc-reel-80\n",
      "M:C\n",
      "L:1/8\n",
      "K:D Major\n",
      "D|G2BG dGBG|FGAF DFFA|BAGF G2BG|AGDF GBAG|F4 E2G2|!\n",
      "G2BG dGBG|defg e2cd|edBA G2Bd|!\n",
      "AGFA DGG2|Bded c2AG|ABAG FABc|d2fe d2:|!\n",
      "cd|e2-28\n",
      "M:C\n",
      "L:1/8\n",
      "K:D Major\n",
      "DFG AFD|ABd AFD|gfe ede|fdB AFA|!\n",
      "FAF AFE|DFA d2e|fdB cAF|AGF G2:|!\n",
      "g|fdd edc|f2f gfg|a2f g2e|!\n",
      "f2df g2ed|c2af g2ed|c2A4 A2|g2a2 bgg2|(3baf gfge|d2d^c d2cA|!\n",
      "BGBd BdBd|gabg ^dgga|bgab aged|cBcA G2:|!\n"
     ]
    }
   ],
   "source": [
    "### Play back generated songs ###\n",
    "print('http://www.mandolintab.net/abcconverter.php')\n",
    "generated_songs = audio_helpers.extract_song_snippet(generated_text)\n",
    "\n",
    "for i, song in enumerate(generated_songs): \n",
    "      print(song)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('base': conda)",
   "language": "python",
   "name": "python37664bitbaseconda7aa6840857c04f3097ec05d42b7cd720"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
